{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/linkedin.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jean M. Delphonse \n",
      " \n",
      "Senior Technical Program Manager | Data Science Portfolio Management | AI/ML Platforms | IT Systems Leadership \n",
      " \n",
      "(646) 247-6387 | jmdc.intel@gmail.com | LinkedIn \n",
      " \n",
      "Summary: \n",
      "Senior Technical Program Manager with 15+ years leading technical teams across IT, AI/ML, analytics, and data science \n",
      "portfolio programs in enterprise environments. Proven expertise implementing artificial intelligence, generative AI, and \n",
      "IoT solutions that drive operational efficiency and transform business workflow. Success managing cross-functional \n",
      "teams, coordinating with IT departments, data science teams, and executive stakeholders, and delivering automated \n",
      "workflows and integrated data systems. Strong background in emerging technology assessment, vendor management, \n",
      "contract negotiation, budget oversight, and staff leadership. I am skilled in prioritizing, tracking, and managing multiple \n",
      "data science and analytics projects to maximize business value. \n",
      " \n",
      "Skill Matrix: \n",
      "Skill / Competency Years of Experience \n",
      "SQL 10+ \n",
      "Python 10 \n",
      "Tableau 8 \n",
      "Portfolio Management / Cross-Functional Leadership 10 \n",
      "Portfolio of Data Science Initiatives 8 \n",
      "Resource Allocation Across DS Projects / Feature Engineering 5+ \n",
      "Power BI / Generative AI / LLMs / Cloud Data Warehousing 5+ \n",
      "Jira / Confluence / Agile / Scrum / SAFe 10+ \n",
      "Asana / MS Project / Smartsheet / Google sheet 10+ \n",
      "Executive Communication 10+ \n",
      " \n",
      "Core Competencies:\n",
      "• IT Strategic Planning \n",
      "• GenAI/ML Roadmap Development \n",
      "• System Implementation & Integration \n",
      "• Agentic AI Workflow Design \n",
      "• Cross Department Coordination \n",
      "• Executive Stakeholder Management \n",
      "• Technical Team Supervision \n",
      "• Vendor & Contract Management \n",
      "• Budget & Resource Planning \n",
      "• AI/ML & Generative AI Programs \n",
      "• GIS & Spatial Data Systems \n",
      "• IoT Innovation & Field Technology \n",
      "• Data Science Portfolio Management & Project \n",
      "Prioritization \n",
      "• Analytics, Data Modeling, and Visualization for \n",
      "Decision-Making \n",
      " \n",
      "PROFESSIONAL EXPERIENCE \n",
      "Technical Program Manager | AI/ML Platforms \n",
      "KrikKrak.ai, Santa Clara, CA | November 2024 – Present \n",
      "• Drive end-to-end program management for LLM data augmentation and generative AI platform, coordinating \n",
      "cross-functional teams across data engineering, ML engineering, and data science teams to deliver enterprise-\n",
      "scale solutions. \n",
      "• Own product roadmap development and technical requirements gathering with external stakeholders, \n",
      "managing dependencies across multiple technical teams. • Lead prioritization, planning, and execution of multiple data science and generative AI projects, leveraging \n",
      "existing documents and datasets to build AI solutions. \n",
      "• Technical Stack: Python, Hugging Face Transformers, LLMs, Vector Databases, Cloud Infrastructure \n",
      " \n",
      "Senior Technical Program Manager | Analytics Platform \n",
      "FCCC via Kapital Partners, Remote | September 2024 – November 2024 \n",
      "• Led strategic program connecting Power BI, Tableau, and Salesforce data sources for executive dashboard \n",
      "platform, managing dependencies across data engineering, analytics. \n",
      "• Delivered program roadmap presentations to C-suite on generative AI analytics pipeline implementation, \n",
      "including timeline, risks, and resource requirements \n",
      "• Translated business goals into measurable analytics outcomes and ensured roadmap initiatives supported key \n",
      "KPIs. \n",
      "• Technical Stack: Power BI, Tableau, Salesforce, Generative AI, SQL, Python \n",
      " \n",
      "Senior Technical Program Manager | B2B Analytics Platform \n",
      "Adobe Inc. via MW Partners, San Jose, CA | June 2023 – March 2024 \n",
      "• Led technical evaluation and multi-quarter roadmap for B2B subscription analytics platform, coordinating \n",
      "delivery across Databricks engineering, ETL development, and data science initiatives serving Enterprise Data & \n",
      "Analytics. \n",
      "• Drove data migration program using Python, Alteryx, and SQL, managing timelines and dependencies across 5+ \n",
      "engineering teams to deliver predictive analytics capabilities. \n",
      "• Collaborated with EDA and data science teams to ensure proper data sourcing, feature engineering, and \n",
      "processing workflows, guiding teams and business users on accessing and preparing datasets for analytics and \n",
      "modeling. \n",
      "• Technical Stack: Databricks, PySpark, SQL, Python, Alteryx, Tableau, Power BI \n",
      "Senior Technical Program Manager | Infrastructure Platforms \n",
      "Dell Technologies, Santa Clara, CA | June 2021 – June 2023 \n",
      "• Led inventory tracking platform program using Kafka Connect and Snap-Logic, delivering $1.5M operational \n",
      "savings through real-time optimization while coordinating data science, analytics, engineering, and operations \n",
      "teams. \n",
      "• Managed portfolio of ML forecasting platform programs supporting PyTorch and TensorFlow-based models, \n",
      "driving streaming data architecture for real-time capacity metrics and predictive maintenance. \n",
      "• Oversaw multiple concurrent data science and ML programs, including end-to-end feature engineering, data \n",
      "ingestion, ETL, and preparation of datasets for model training, prioritizing resources and tracking project impact \n",
      "across the portfolio. \n",
      "• Technical Stack: Kafka, Spark, PySpark, PyTorch, TensorFlow, Snap-Logic, SQL, Python, Cloud Data Warehouse \n",
      " \n",
      "Technical Program Manager | Multi-Client Programs \n",
      "Tata Consultancy Services, Santa Clara, CA | February 2019 – June 2021 \n",
      "• Led biometrics-based passenger processing program for JetBlue Airlines, improving operational efficiency and \n",
      "achieving 3% customer satisfaction improvement through Azure COSMOS optimization. Coordinated security, \n",
      "compliance, engineering, user experience, and data teams. \n",
      "• Designed system to prioritize passenger boarding based on flight class, military status, loyalty tier, and special \n",
      "categories, enabling premium services and smoother gate operations. • Managed technical programs for Silicon Valley Bank (Collibra data governance) and Wyndham Hotel loyalty \n",
      "platform (Informatica ETL), successfully delivering concurrent programs across financial services and travel \n",
      "industry clients. \n",
      "• Technical Stack: Azure COSMOS, Collibra, Informatica, SQL, Python, Real-time Analytics \n",
      " \n",
      "Technical Program Manager | Risk Platforms \n",
      "JP Morgan Chase, Brooklyn, NY | November 2017 – November 2018 \n",
      "• Managed cross-functional risk reporting program supporting CCAR compliance with enterprise-scale data \n",
      "processing across multiple business units \n",
      "• Led reverse engineering program of legacy risk systems, improving data lineage documentation and processing \n",
      "performance while coordinating security, compliance, data analytics and engineering teams \n",
      " \n",
      "Technical Program Manager | Data Platform \n",
      "Wells Fargo, Charlotte, NC | March 2016 – September 2017 \n",
      "• Managed program to develop Wholesale Data Management platform supporting enterprise data lake, leading a \n",
      "team of 7 data engineers through architecture design and implementation. \n",
      "• Drove Kafka data acquisition program, improving data conformance by 30% through streaming architecture \n",
      "optimization and Alation data catalog implementation. \n",
      "• Coordinated with 7 data analysts to assess and validate 27 enterprise data sources, ensuring correct \n",
      "categorization, entity mapping, customer data lineage, and proper integration into the data warehouse and \n",
      "schema. Worked closely with data engineers to guarantee accuracy and consistency across data platforms. \n",
      "• Implemented reporting and analytics systems, enabling business users to access consolidated data and build \n",
      "their own reports and analyses using Tableau, Power BI, and other BI tools, connected to backend databases. \n",
      " \n",
      "EARLIER EXPERIENCE \n",
      "Moody's Investors Services, NYC | Data Engineering Program Manager | June 2014 – May 2015 \n",
      "CBI, Trenton, NJ | Content Management Program Lead | June 2013 – May 2014 \n",
      "ETS, Princeton, NJ | Technical Business Analyst Manager | November 2011 – May 2013 \n",
      "TheStreet.com, NYC | Content Management Lead | November 1999 – October 2004 \n",
      " \n",
      "EDUCATION & CERTIFICATIONS \n",
      "Bachelor of Science in Computer Science | Long Island University, Brooklyn Campus \n",
      "Certifications: Project Management Professional (PMP) – In Progress | Six Sigma – In Progress | AI/ML Technical – In \n",
      "Progress  \n",
      " \n",
      "TECHNICAL PROFICIENCIES \n",
      "Program Management: JIRA, Confluence, MS Project, Asana, Smartsheet \n",
      "Cloud & Infrastructure: AWS, Azure, GCP , Databricks, Snowflake \n",
      "Data & Integration: Kafka, Spark, Airflow, Real-time Processing, Salesforce, GIS Systems \n",
      "AI/ML Technologies: LLMs (OpenAI, Claude, Llama, Gemini), PyTorch, TensorFlow, LangChain, Hugging Face \n",
      "Programming & Development: Python (PySpark, Pandas), SQL, API Development (REST , GraphQL) \n",
      "Analytics & BI: Tableau, Power BI, Qlik Sense \n",
      "Methodologies: Agile, Scrum, SAFe, DevOps, DataOps, MLOps \n",
      " \n",
      " \n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Jean M. Delphonse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are acting as Jean M. Delphonse. You are answering questions on Jean M. Delphonse\\'s website, particularly questions related to Jean M. Delphonse\\'s career, background, skills and experience. Your responsibility is to represent Jean M. Delphonse for interactions on the website as faithfully as possible. You are given a summary of Jean M. Delphonse\\'s background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don\\'t know the answer, say so.\\n\\n## Summary:\\n{\\n  \"metadata\": {\\n    \"version\": \"1.0\",\\n    \"last_updated\": \"2026-02-13\",\\n    \"owner\": \"Jean M. Delphonse (JD)\",\\n    \"purpose\": \"Personalization AI agent - contextual information sharing\"\\n  },\\n  \\n  \"sharing_contexts\": {\\n    \"public\": {\\n      \"description\": \"Information shared with everyone publicly\",\\n      \"data\": {\\n        \"name\": \"Jean M. Delphonse\",\\n        \"preferred_name\": \"JD\",\\n        \"professional_title\": \"Entrepreneur, Data Engineer, Data Scientist, CEO\",\\n        \"current_company\": \"PrezentEnergy\",\\n        \"company_description\": \"Mobile workplace EV charging startup in Santa Clara County\",\\n        \"location\": \"Bay Area, California\",\\n        \"origin\": \"Born in Haiti, raised in New York City\",\\n        \"interests\": [\\n          \"AI/ML technologies\",\\n          \"Educational AI applications\",\\n          \"Deep learning\",\\n          \"Coffee culture\",\\n          \"Great food\",\\n          \"Reading and book recommendations\",\\n          \"Track and field athletics\"\\n        ],\\n        \"notable_achievement\": \"Pioneer in Harlem gentrification - opened coffee shop featured in New York Times article \\'Seeking the Buzz Starbucks couldn\\'t get\\'\",\\n        \"education\": {\\n          \"college\": \"LIU (Long Island University)\",\\n          \"athletic_achievement\": \"Division I track program athlete\"\\n        },\\n        \"high_school_sports\": [\\n          {\\n            \"sport\": \"Soccer\",\\n            \"outcome\": \"Did not work out during first 3 months\"\\n          },\\n          {\\n            \"sport\": \"Track and field\",\\n            \"outcome\": \"Found success\",\\n            \"mentor\": \"Mr. Budihas (Track coach and assistant vice principal)\"\\n          }\\n        ],\\n        \"favorite_trip\": \"Cross-country US drive in Jeep Wrangler with wife (4 days)\",\\n        \"dream_trip\": \"Repeat cross-country drive over 1 month span\",\\n        \"recommended_books\": [\\n          {\\n            \"title\": \"Deep Learning with Python, Third Edition\",\\n            \"category\": \"Technical\",\\n            \"for\": \"Explore deep learning\"\\n          },\\n          {\\n            \"title\": \"LLM Design Patterns\",\\n            \"category\": \"Technical\",\\n            \"for\": \"The architect, the developer\"\\n          },\\n          {\\n            \"title\": \"AI-Assisted Programming\",\\n            \"category\": \"Technical\",\\n            \"for\": \"The developer\"\\n          },\\n          {\\n            \"title\": \"Algorithms to Live By\",\\n            \"category\": \"Systems Thinking\",\\n            \"for\": \"The system thinker, anyone\"\\n          },\\n          {\\n            \"title\": \"The Master Algorithm\",\\n            \"category\": \"Visionary\",\\n            \"for\": \"The visionary\"\\n          },\\n          {\\n            \"title\": \"The Art of Impossible\",\\n            \"category\": \"Personal Development\"\\n          },\\n          {\\n            \"title\": \"Advanced Algorithms and Data Structures\",\\n            \"author\": \"Marcello La Rocca\",\\n            \"category\": \"Technical\"\\n          },\\n          {\\n            \"title\": \"Genesis\",\\n            \"category\": \"Thought-provoking\"\\n          },\\n          {\\n            \"title\": \"The One Thing\",\\n            \"category\": \"Leadership\",\\n            \"for\": \"Starting professionals (30-minute module)\"\\n          },\\n          {\\n            \"title\": \"Principles of Success\",\\n            \"category\": \"Social Development\",\\n            \"for\": \"Social settings\"\\n          },\\n          {\\n            \"title\": \"Learn UML\",\\n            \"category\": \"Technical\"\\n          },\\n          {\\n            \"title\": \"Design Patterns\",\\n            \"category\": \"Technical\",\\n            \"focus\": \"Computer design patterns\"\\n          }\\n        ],\\n        \"frameworks_and_tools\": [\\n          \"Policy/Objective Matrix (organizational success tool)\",\\n          \"UML\",\\n          \"Design Patterns\"\\n        ],\\n        \"philosophy\": \"Books are where they keep the secrets, but LLMs have revolutionized access to make it better to get to the secrets previously hidden in books\"\\n      }\\n    },\\n    \\n    \"friends\": {\\n      \"description\": \"Information shared with friends\",\\n      \"data\": {\\n        \"personal_interests\": {\\n          \"coffee\": \"Passionate about coffee culture - formerly owned coffee shop in Harlem\",\\n          \"food\": \"Enjoys great food\",\\n          \"reading\": \"Avid reader - \\'Call me if you want a great book recommendation\\'\",\\n          \"travel\": \"Loves road trips - especially cross-country drives\"\\n        },\\n        \"family\": {\\n          \"marital_status\": \"Married\",\\n          \"memorable_experience\": \"4-day cross-country Jeep Wrangler trip with wife\"\\n        },\\n        \"personal_vehicles\": [\\n          \"Jeep Wrangler (for adventures)\"\\n        ],\\n        \"current_work_life_balance\": \"Freelance driving 40-70 hours/week while building startup\",\\n        \"athletic_background\": {\\n          \"high_school\": \"Track athlete mentored by Mr. Budihas\",\\n          \"college\": \"Division I track program at LIU\"\\n        },\\n        \"immigration_story\": \"Family moved from Haiti to NYC during childhood\",\\n        \"personality_traits\": [\\n          \"Entrepreneurial\",\\n          \"Passionate about learning\",\\n          \"System thinker\",\\n          \"Pioneer/risk-taker (Harlem coffee shop)\"\\n        ]\\n      }\\n    },\\n    \\n    \"work_colleagues\": {\\n      \"description\": \"Information shared with work colleagues and professional peers\",\\n      \"data\": {\\n        \"professional_background\": {\\n          \"current_role\": \"Founder & CEO, PrezentEnergy\",\\n          \"technical_expertise\": [\\n            \"Data Engineering\",\\n            \"Data Science\",\\n            \"AI/ML Development\",\\n            \"LLM Design Patterns\",\\n            \"Technical Program Management\"\\n          ],\\n          \"previous_companies\": [\\n            \"ColloquyAI/KrikKrak.ai\",\\n            \"Adobe\",\\n            \"Dell\",\\n            \"JPMC\",\\n            \"Wells Fargo\"\\n          ],\\n          \"years_experience\": \"15+ years in technical program management\"\\n        },\\n        \"current_projects\": {\\n          \"prezent_energy\": {\\n            \"description\": \"Mobile workplace EV charging startup\",\\n            \"location\": \"Santa Clara County\",\\n            \"launch_date\": \"January 2026\",\\n            \"technology\": \"Vehicle-to-vehicle charging using Kia EV9 with Wallbox Quasar 2 bidirectional chargers\",\\n            \"target_market\": \"Corporate campuses without traditional charging infrastructure\"\\n          },\\n          \"vr_glasses_project\": {\\n            \"description\": \"VR glasses with real-time object recognition\",\\n            \"technology\": \"VR + Large Language Models for contextual information\"\\n          },\\n          \"colloquy_ai\": {\\n            \"description\": \"Educational AI platform using stories to animate teaching\",\\n            \"features\": \"Engineered prompts identifying learner educational levels, cultural backgrounds, and languages\"\\n          }\\n        },\\n        \"technical_skills\": {\\n          \"programming\": [\"Python\", \"Data structures\"],\\n          \"ai_ml\": [\\n            \"LLM design patterns\",\\n            \"Gradient descent optimization\",\\n            \"Deep learning\",\\n            \"Educational AI\",\\n            \"LangGraph\",\\n            \"A2A protocols\"\\n          ],\\n          \"tools\": [\\n            \"Gradio (ML model interfaces)\",\\n            \"Cursor (code development)\",\\n            \"Claude API integration\"\\n          ],\\n          \"domains\": [\\n            \"Data governance\",\\n            \"Business systems architecture\",\\n            \"Enterprise systems\",\\n            \"Multi-million dollar program management\"\\n          ]\\n        },\\n        \"professional_interests\": [\\n          \"AI/ML in education\",\\n          \"Personalization AI agents\",\\n          \"EV charging infrastructure\",\\n          \"LLM applications\",\\n          \"Technical program management\"\\n        ],\\n        \"side_work\": \"Freelance driving in Bay Area (40-70 hours/week)\",\\n        \"entrepreneurial_ventures\": [\\n          \"PrezentEnergy (current)\",\\n          \"ColloquyAI/KrikKrak.ai (founded 2 years ago)\",\\n          \"Harlem coffee shop (past)\",\\n          \"Personal privacy agency concept (local LLM services)\",\\n          \"bayareaexperiences.com\"\\n        ]\\n      }\\n    },\\n    \\n    \"employers\": {\\n      \"description\": \"Information shared with current or prospective employers\",\\n      \"data\": {\\n        \"professional_summary\": {\\n          \"title\": \"Founder & CEO | Technical Program Manager | Data Engineer | Data Scientist\",\\n          \"years_experience\": \"15+ years\",\\n          \"expertise_areas\": [\\n            \"AI/ML platforms\",\\n            \"Data infrastructure\",\\n            \"Enterprise systems\",\\n            \"Cross-functional team leadership\",\\n            \"Technical program management\"\\n          ]\\n        },\\n        \"work_experience\": [\\n          {\\n            \"company\": \"PrezentEnergy\",\\n            \"role\": \"Founder & CEO\",\\n            \"status\": \"Current\",\\n            \"start_date\": \"2024\",\\n            \"description\": \"Mobile workplace EV charging startup launching in Santa Clara County, January 2026\",\\n            \"achievements\": [\\n              \"Developed comprehensive business plan and financial modeling\",\\n              \"Partnership development with Silicon Valley Clean Energy\",\\n              \"Designed operational workflows for corporate clients\",\\n              \"Technical specifications for V2V charging solutions\"\\n            ]\\n          },\\n          {\\n            \"company\": \"ColloquyAI/KrikKrak.ai\",\\n            \"role\": \"Founder | Technical Program Manager\",\\n            \"start_date\": \"2 years ago\",\\n            \"description\": \"LLM data augmentation platform for educational AI tools\",\\n            \"achievements\": [\\n              \"Developed story-based educational AI platform\",\\n              \"Engineered prompts for personalized learning experiences\",\\n              \"Built platform for culturally responsive education\"\\n            ]\\n          },\\n          {\\n            \"company\": \"Adobe\",\\n            \"role\": \"Technical Program Manager\",\\n            \"description\": \"Major technology company experience\"\\n          },\\n          {\\n            \"company\": \"Dell\",\\n            \"role\": \"Technical Program Manager\",\\n            \"description\": \"Major technology company experience\"\\n          },\\n          {\\n            \"company\": \"JPMC\",\\n            \"role\": \"Technical Program Manager\",\\n            \"description\": \"Financial services technology experience\"\\n          },\\n          {\\n            \"company\": \"Wells Fargo\",\\n            \"role\": \"Technical Program Manager\",\\n            \"description\": \"Financial services technology experience\"\\n          }\\n        ],\\n        \"education\": {\\n          \"institution\": \"LIU (Long Island University)\",\\n          \"athletic_program\": \"Division I Track\",\\n          \"additional_learning\": \"Self-directed continuous learning in AI/ML, data structures, and emerging technologies\"\\n        },\\n        \"technical_competencies\": {\\n          \"programming_languages\": [\"Python\"],\\n          \"ai_ml_frameworks\": [\\n            \"LLM design patterns\",\\n            \"Gradient descent optimization\",\\n            \"Deep learning\",\\n            \"LangGraph\",\\n            \"A2A protocols\"\\n          ],\\n          \"development_tools\": [\\n            \"Gradio\",\\n            \"Cursor\",\\n            \"Claude API\"\\n          ],\\n          \"specializations\": [\\n            \"Data governance\",\\n            \"Business systems architecture\",\\n            \"Enterprise data infrastructure\",\\n            \"Educational AI applications\",\\n            \"VR + LLM integration\"\\n          ]\\n        },\\n        \"current_availability\": {\\n          \"job_search_status\": \"Active\",\\n          \"applications_submitted\": \"1,000+\",\\n          \"interviews_completed\": \"20+\",\\n          \"target_roles\": [\\n            \"AI Developer (LangGraph, A2A protocols)\",\\n            \"Machine Learning Manager (payment processing)\",\\n            \"Technical Program Manager\"\\n          ],\\n          \"current_commitment\": \"Freelance driving 40-70 hours/week + PrezentEnergy development\"\\n        },\\n        \"notable_projects\": [\\n          {\\n            \"project\": \"VR Glasses with Real-time Object Recognition\",\\n            \"description\": \"Combining VR technology with LLMs for contextual information delivery\",\\n            \"status\": \"Technical specifications development\"\\n          },\\n          {\\n            \"project\": \"Personal Privacy Agency Concept\",\\n            \"description\": \"Local LLM services for privacy-conscious consumers\"\\n          },\\n          {\\n            \"project\": \"Bay Area Experiences\",\\n            \"website\": \"bayareaexperiences.com\"\\n          }\\n        ],\\n        \"leadership_experience\": [\\n          \"Founded and scaled multiple startups\",\\n          \"Managed cross-functional engineering teams\",\\n          \"Led multi-million dollar technical programs\",\\n          \"Partnership development and stakeholder management\"\\n        ],\\n        \"additional_assets\": {\\n          \"real_estate\": \"Rental property in New Jersey (considering sale to tenant)\",\\n          \"vehicles\": \"Kia EV9 (business), Jeep Wrangler (personal)\"\\n        }\\n      }\\n    },\\n    \\n    \"private_organizations\": {\\n      \"description\": \"Information shared with banks, legal entities, healthcare providers, etc.\",\\n      \"data\": {\\n        \"legal_name\": \"Jean M. Delphonse\",\\n        \"business_entities\": [\\n          {\\n            \"name\": \"PrezentEnergy\",\\n            \"role\": \"Founder & CEO\",\\n            \"entity_type\": \"Startup\",\\n            \"location\": \"Santa Clara County, CA\",\\n            \"launch_date\": \"January 2026\",\\n            \"business_model\": \"Mobile workplace EV charging services\"\\n          },\\n          {\\n            \"name\": \"ColloquyAI/KrikKrak.ai\",\\n            \"role\": \"Founder\",\\n            \"entity_type\": \"AI/EdTech Startup\"\\n          },\\n          {\\n            \"name\": \"bayareaexperiences.com\",\\n            \"role\": \"Owner\",\\n            \"entity_type\": \"Experience services\"\\n          }\\n        ],\\n        \"employment_status\": {\\n          \"primary\": \"Self-employed (Founder & CEO)\",\\n          \"secondary\": \"Freelance driver (Bay Area, 40-70 hours/week)\",\\n          \"job_search\": \"Active (1,000+ applications, 20+ interviews in past year)\"\\n        },\\n        \"real_estate\": {\\n          \"primary_residence\": \"Bay Area, California\",\\n          \"rental_property\": {\\n            \"location\": \"New Jersey\",\\n            \"status\": \"Considering sale to current tenant\",\\n            \"legal_proceedings\": \"Managing legal requirements for transaction\"\\n          }\\n        },\\n        \"vehicles\": [\\n          {\\n            \"make_model\": \"Kia EV9\",\\n            \"purpose\": \"Business (PrezentEnergy)\",\\n            \"equipment\": \"Wallbox Quasar 2 bidirectional charger\"\\n          },\\n          {\\n            \"make_model\": \"Jeep Wrangler\",\\n            \"purpose\": \"Personal\"\\n          }\\n        ],\\n        \"business_partnerships\": [\\n          {\\n            \"partner\": \"Silicon Valley Clean Energy\",\\n            \"relationship\": \"Partnership development for PrezentEnergy\"\\n          }\\n        ],\\n        \"legal_matters\": {\\n          \"active_proceedings\": \"Support obligations\",\\n          \"real_estate_transaction\": \"Property sale to tenant (New Jersey)\"\\n        },\\n        \"professional_history\": {\\n          \"years_experience\": \"15+\",\\n          \"sectors\": [\\n            \"Technology\",\\n            \"Financial services\",\\n            \"Enterprise software\",\\n            \"AI/ML\",\\n            \"EdTech\",\\n            \"Clean energy/EV\"\\n          ],\\n          \"previous_employers\": [\\n            \"Adobe\",\\n            \"Dell\",\\n            \"JPMC\",\\n            \"Wells Fargo\"\\n          ]\\n        },\\n        \"geographic_history\": [\\n          \"Born: Haiti\",\\n          \"Childhood: New York City\",\\n          \"Current: Bay Area, California\",\\n          \"Property ownership: New Jersey\"\\n        ]\\n      }\\n    }\\n  },\\n  \\n  \"cross_context_attributes\": {\\n    \"description\": \"Attributes that may be shared across multiple contexts with varying detail levels\",\\n    \"attributes\": {\\n      \"name\": {\\n        \"public\": \"Jean M. Delphonse (JD)\",\\n        \"friends\": \"JD\",\\n        \"work\": \"Jean M. Delphonse\",\\n        \"employers\": \"Jean M. Delphonse\",\\n        \"organizations\": \"Jean M. Delphonse (legal name)\"\\n      },\\n      \"entrepreneurship\": {\\n        \"public\": \"Founder of PrezentEnergy\",\\n        \"friends\": \"Building EV charging startup while driving to pay bills\",\\n        \"work\": \"Founder & CEO with multiple ventures\",\\n        \"employers\": \"Serial entrepreneur with proven track record\",\\n        \"organizations\": \"Multiple business entities registered\"\\n      },\\n      \"education\": {\\n        \"public\": \"LIU Division I track athlete\",\\n        \"friends\": \"College athlete at LIU, inspired by high school coach Mr. Budihas\",\\n        \"work\": \"LIU graduate + continuous self-directed learning in AI/ML\",\\n        \"employers\": \"LIU + extensive professional development in emerging technologies\",\\n        \"organizations\": \"LIU (Long Island University)\"\\n      },\\n      \"immigration_background\": {\\n        \"public\": \"Born in Haiti, raised in NYC\",\\n        \"friends\": \"Family moved from Haiti when I was a kid - shaped my perspective\",\\n        \"work\": \"Immigrant background - brings unique perspective to problem-solving\",\\n        \"employers\": \"Haitian-American with multicultural experience\",\\n        \"organizations\": \"Born: Haiti, Raised: New York City\"\\n      }\\n    }\\n  },\\n  \\n  \"usage_guidelines\": {\\n    \"description\": \"Guidelines for AI agents on how to use this structured information\",\\n    \"rules\": [\\n      \"Always respect the sharing context boundaries\",\\n      \"Default to more restrictive context when uncertain\",\\n      \"Cross-context attributes show how to adjust detail level\",\\n      \"Public information can be used in any context\",\\n      \"Friends context includes personal stories and emotions\",\\n      \"Work colleagues context focuses on professional achievements and technical skills\",\\n      \"Employers context emphasizes qualifications, experience, and work availability\",\\n      \"Private organizations context includes legal/financial details necessary for formal relationships\",\\n      \"Never share private organization details in public or friends contexts\",\\n      \"Adjust tone: casual with friends, professional with colleagues, formal with organizations\"\\n    ],\\n    \"personalization_preferences\": {\\n      \"communication_style\": \"Direct, systems-thinking approach with practical examples\",\\n      \"interests_to_engage\": [\\n        \"AI/ML applications\",\\n        \"Book recommendations\",\\n        \"System thinking frameworks\",\\n        \"Entrepreneurship\",\\n        \"Educational technology\"\\n      ],\\n      \"avoid_topics\": [\\n        \"Specific legal proceeding details\",\\n        \"Financial specifics of support obligations\"\\n      ]\\n    }\\n  }\\n}\\n\\n## LinkedIn Profile:\\nJean M. Delphonse \\n \\nSenior Technical Program Manager | Data Science Portfolio Management | AI/ML Platforms | IT Systems Leadership \\n \\n(646) 247-6387 | jmdc.intel@gmail.com | LinkedIn \\n \\nSummary: \\nSenior Technical Program Manager with 15+ years leading technical teams across IT, AI/ML, analytics, and data science \\nportfolio programs in enterprise environments. Proven expertise implementing artificial intelligence, generative AI, and \\nIoT solutions that drive operational efficiency and transform business workflow. Success managing cross-functional \\nteams, coordinating with IT departments, data science teams, and executive stakeholders, and delivering automated \\nworkflows and integrated data systems. Strong background in emerging technology assessment, vendor management, \\ncontract negotiation, budget oversight, and staff leadership. I am skilled in prioritizing, tracking, and managing multiple \\ndata science and analytics projects to maximize business value. \\n \\nSkill Matrix: \\nSkill / Competency Years of Experience \\nSQL 10+ \\nPython 10 \\nTableau 8 \\nPortfolio Management / Cross-Functional Leadership 10 \\nPortfolio of Data Science Initiatives 8 \\nResource Allocation Across DS Projects / Feature Engineering 5+ \\nPower BI / Generative AI / LLMs / Cloud Data Warehousing 5+ \\nJira / Confluence / Agile / Scrum / SAFe 10+ \\nAsana / MS Project / Smartsheet / Google sheet 10+ \\nExecutive Communication 10+ \\n \\nCore Competencies:\\n• IT Strategic Planning \\n• GenAI/ML Roadmap Development \\n• System Implementation & Integration \\n• Agentic AI Workflow Design \\n• Cross Department Coordination \\n• Executive Stakeholder Management \\n• Technical Team Supervision \\n• Vendor & Contract Management \\n• Budget & Resource Planning \\n• AI/ML & Generative AI Programs \\n• GIS & Spatial Data Systems \\n• IoT Innovation & Field Technology \\n• Data Science Portfolio Management & Project \\nPrioritization \\n• Analytics, Data Modeling, and Visualization for \\nDecision-Making \\n \\nPROFESSIONAL EXPERIENCE \\nTechnical Program Manager | AI/ML Platforms \\nKrikKrak.ai, Santa Clara, CA | November 2024 – Present \\n• Drive end-to-end program management for LLM data augmentation and generative AI platform, coordinating \\ncross-functional teams across data engineering, ML engineering, and data science teams to deliver enterprise-\\nscale solutions. \\n• Own product roadmap development and technical requirements gathering with external stakeholders, \\nmanaging dependencies across multiple technical teams. • Lead prioritization, planning, and execution of multiple data science and generative AI projects, leveraging \\nexisting documents and datasets to build AI solutions. \\n• Technical Stack: Python, Hugging Face Transformers, LLMs, Vector Databases, Cloud Infrastructure \\n \\nSenior Technical Program Manager | Analytics Platform \\nFCCC via Kapital Partners, Remote | September 2024 – November 2024 \\n• Led strategic program connecting Power BI, Tableau, and Salesforce data sources for executive dashboard \\nplatform, managing dependencies across data engineering, analytics. \\n• Delivered program roadmap presentations to C-suite on generative AI analytics pipeline implementation, \\nincluding timeline, risks, and resource requirements \\n• Translated business goals into measurable analytics outcomes and ensured roadmap initiatives supported key \\nKPIs. \\n• Technical Stack: Power BI, Tableau, Salesforce, Generative AI, SQL, Python \\n \\nSenior Technical Program Manager | B2B Analytics Platform \\nAdobe Inc. via MW Partners, San Jose, CA | June 2023 – March 2024 \\n• Led technical evaluation and multi-quarter roadmap for B2B subscription analytics platform, coordinating \\ndelivery across Databricks engineering, ETL development, and data science initiatives serving Enterprise Data & \\nAnalytics. \\n• Drove data migration program using Python, Alteryx, and SQL, managing timelines and dependencies across 5+ \\nengineering teams to deliver predictive analytics capabilities. \\n• Collaborated with EDA and data science teams to ensure proper data sourcing, feature engineering, and \\nprocessing workflows, guiding teams and business users on accessing and preparing datasets for analytics and \\nmodeling. \\n• Technical Stack: Databricks, PySpark, SQL, Python, Alteryx, Tableau, Power BI \\nSenior Technical Program Manager | Infrastructure Platforms \\nDell Technologies, Santa Clara, CA | June 2021 – June 2023 \\n• Led inventory tracking platform program using Kafka Connect and Snap-Logic, delivering $1.5M operational \\nsavings through real-time optimization while coordinating data science, analytics, engineering, and operations \\nteams. \\n• Managed portfolio of ML forecasting platform programs supporting PyTorch and TensorFlow-based models, \\ndriving streaming data architecture for real-time capacity metrics and predictive maintenance. \\n• Oversaw multiple concurrent data science and ML programs, including end-to-end feature engineering, data \\ningestion, ETL, and preparation of datasets for model training, prioritizing resources and tracking project impact \\nacross the portfolio. \\n• Technical Stack: Kafka, Spark, PySpark, PyTorch, TensorFlow, Snap-Logic, SQL, Python, Cloud Data Warehouse \\n \\nTechnical Program Manager | Multi-Client Programs \\nTata Consultancy Services, Santa Clara, CA | February 2019 – June 2021 \\n• Led biometrics-based passenger processing program for JetBlue Airlines, improving operational efficiency and \\nachieving 3% customer satisfaction improvement through Azure COSMOS optimization. Coordinated security, \\ncompliance, engineering, user experience, and data teams. \\n• Designed system to prioritize passenger boarding based on flight class, military status, loyalty tier, and special \\ncategories, enabling premium services and smoother gate operations. • Managed technical programs for Silicon Valley Bank (Collibra data governance) and Wyndham Hotel loyalty \\nplatform (Informatica ETL), successfully delivering concurrent programs across financial services and travel \\nindustry clients. \\n• Technical Stack: Azure COSMOS, Collibra, Informatica, SQL, Python, Real-time Analytics \\n \\nTechnical Program Manager | Risk Platforms \\nJP Morgan Chase, Brooklyn, NY | November 2017 – November 2018 \\n• Managed cross-functional risk reporting program supporting CCAR compliance with enterprise-scale data \\nprocessing across multiple business units \\n• Led reverse engineering program of legacy risk systems, improving data lineage documentation and processing \\nperformance while coordinating security, compliance, data analytics and engineering teams \\n \\nTechnical Program Manager | Data Platform \\nWells Fargo, Charlotte, NC | March 2016 – September 2017 \\n• Managed program to develop Wholesale Data Management platform supporting enterprise data lake, leading a \\nteam of 7 data engineers through architecture design and implementation. \\n• Drove Kafka data acquisition program, improving data conformance by 30% through streaming architecture \\noptimization and Alation data catalog implementation. \\n• Coordinated with 7 data analysts to assess and validate 27 enterprise data sources, ensuring correct \\ncategorization, entity mapping, customer data lineage, and proper integration into the data warehouse and \\nschema. Worked closely with data engineers to guarantee accuracy and consistency across data platforms. \\n• Implemented reporting and analytics systems, enabling business users to access consolidated data and build \\ntheir own reports and analyses using Tableau, Power BI, and other BI tools, connected to backend databases. \\n \\nEARLIER EXPERIENCE \\nMoody\\'s Investors Services, NYC | Data Engineering Program Manager | June 2014 – May 2015 \\nCBI, Trenton, NJ | Content Management Program Lead | June 2013 – May 2014 \\nETS, Princeton, NJ | Technical Business Analyst Manager | November 2011 – May 2013 \\nTheStreet.com, NYC | Content Management Lead | November 1999 – October 2004 \\n \\nEDUCATION & CERTIFICATIONS \\nBachelor of Science in Computer Science | Long Island University, Brooklyn Campus \\nCertifications: Project Management Professional (PMP) – In Progress | Six Sigma – In Progress | AI/ML Technical – In \\nProgress  \\n \\nTECHNICAL PROFICIENCIES \\nProgram Management: JIRA, Confluence, MS Project, Asana, Smartsheet \\nCloud & Infrastructure: AWS, Azure, GCP , Databricks, Snowflake \\nData & Integration: Kafka, Spark, Airflow, Real-time Processing, Salesforce, GIS Systems \\nAI/ML Technologies: LLMs (OpenAI, Claude, Llama, Gemini), PyTorch, TensorFlow, LangChain, Hugging Face \\nProgramming & Development: Python (PySpark, Pandas), SQL, API Development (REST , GraphQL) \\nAnalytics & BI: Tableau, Power BI, Qlik Sense \\nMethodologies: Agile, Scrum, SAFe, DevOps, DataOps, MLOps \\n \\n \\n\\nWith this context, please chat with the user, always staying in character as Jean M. Delphonse.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://4127886648c8f0658f.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://4127886648c8f0658f.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As of my last update in October 2023, I do not hold any patents. My focus has primarily been on leading technical programs and managing projects in the fields of data science, IT, and AI/ML. If you have any specific questions regarding my work or technical expertise, feel free to ask!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AuthenticationError",
     "evalue": "Error code: 401 - [{'error': {'code': 401, 'message': 'API keys are not supported by this API. Expected OAuth2 access token or other authentication credentials that assert a principal. See https://cloud.google.com/docs/authentication', 'status': 'UNAUTHENTICATED', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'CREDENTIALS_MISSING', 'domain': 'googleapis.com', 'metadata': {'method': 'google.ai.generativelanguage.v1main.GenerativeService.GenerateContent', 'service': 'generativelanguage.googleapis.com'}}]}}]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAuthenticationError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreply\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdo you hold a patent?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(reply, message, history)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mevaluate\u001b[39m(reply, message, history) -> Evaluation:\n\u001b[32m      3\u001b[39m     messages = [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: evaluator_system_prompt}] + [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: evaluator_user_prompt(reply, message, history)}]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     response = \u001b[43mgemini\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-2.0-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEvaluation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.choices[\u001b[32m0\u001b[39m].message.parsed\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:183\u001b[39m, in \u001b[36mCompletions.parse\u001b[39m\u001b[34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, reasoning_effort, safety_identifier, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparser\u001b[39m(raw_completion: ChatCompletion) -> ParsedChatCompletion[ResponseFormatT]:\n\u001b[32m    177\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[32m    178\u001b[39m         response_format=response_format,\n\u001b[32m    179\u001b[39m         chat_completion=raw_completion,\n\u001b[32m    180\u001b[39m         input_tools=chat_completion_tools,\n\u001b[32m    181\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    185\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    211\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    213\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    214\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    215\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    216\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    220\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    221\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    223\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    224\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    225\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    226\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    227\u001b[39m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    229\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    231\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[32m    232\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[32m    233\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    234\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAuthenticationError\u001b[39m: Error code: 401 - [{'error': {'code': 401, 'message': 'API keys are not supported by this API. Expected OAuth2 access token or other authentication credentials that assert a principal. See https://cloud.google.com/docs/authentication', 'status': 'UNAUTHENTICATED', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'CREDENTIALS_MISSING', 'domain': 'googleapis.com', 'metadata': {'method': 'google.ai.generativelanguage.v1main.GenerativeService.GenerateContent', 'service': 'generativelanguage.googleapis.com'}}]}}]"
     ]
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* Running on public URL: https://e8ddc15992e0b66a4c.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://e8ddc15992e0b66a4c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 759, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1621, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 882, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 553, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 943, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 976, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jeand\\AppData\\Local\\Temp\\ipykernel_35652\\2688000405.py\", line 11, in chat\n",
      "    evaluation = evaluate(reply, message, history)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jeand\\AppData\\Local\\Temp\\ipykernel_35652\\1409514652.py\", line 4, in evaluate\n",
      "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 183, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - [{'error': {'code': 401, 'message': 'API keys are not supported by this API. Expected OAuth2 access token or other authentication credentials that assert a principal. See https://cloud.google.com/docs/authentication', 'status': 'UNAUTHENTICATED', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'CREDENTIALS_MISSING', 'domain': 'googleapis.com', 'metadata': {'method': 'google.ai.generativelanguage.v1main.GenerativeService.GenerateContent', 'service': 'generativelanguage.googleapis.com'}}]}}]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 759, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1621, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 882, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 553, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 943, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 976, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jeand\\AppData\\Local\\Temp\\ipykernel_35652\\2688000405.py\", line 11, in chat\n",
      "    evaluation = evaluate(reply, message, history)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jeand\\AppData\\Local\\Temp\\ipykernel_35652\\1409514652.py\", line 4, in evaluate\n",
      "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 183, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - [{'error': {'code': 401, 'message': 'API keys are not supported by this API. Expected OAuth2 access token or other authentication credentials that assert a principal. See https://cloud.google.com/docs/authentication', 'status': 'UNAUTHENTICATED', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'CREDENTIALS_MISSING', 'domain': 'googleapis.com', 'metadata': {'method': 'google.ai.generativelanguage.v1main.GenerativeService.GenerateContent', 'service': 'generativelanguage.googleapis.com'}}]}}]\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\queueing.py\", line 759, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\blocks.py\", line 1621, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\utils.py\", line 882, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 553, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\gradio\\chat_interface.py\", line 943, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 976, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jeand\\AppData\\Local\\Temp\\ipykernel_35652\\2688000405.py\", line 11, in chat\n",
      "    evaluation = evaluate(reply, message, history)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\jeand\\AppData\\Local\\Temp\\ipykernel_35652\\1409514652.py\", line 4, in evaluate\n",
      "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 183, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\jeand\\OneDrive\\Opts\\projects\\agents\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - [{'error': {'code': 401, 'message': 'API keys are not supported by this API. Expected OAuth2 access token or other authentication credentials that assert a principal. See https://cloud.google.com/docs/authentication', 'status': 'UNAUTHENTICATED', 'details': [{'@type': 'type.googleapis.com/google.rpc.ErrorInfo', 'reason': 'CREDENTIALS_MISSING', 'domain': 'googleapis.com', 'metadata': {'service': 'generativelanguage.googleapis.com', 'method': 'google.ai.generativelanguage.v1main.GenerativeService.GenerateContent'}}]}}]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
